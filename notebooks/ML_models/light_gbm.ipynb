{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e5e77c",
   "metadata": {},
   "source": [
    "# LightGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503dac0",
   "metadata": {},
   "source": [
    "add main project directory to path to access utils package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbc52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0f653",
   "metadata": {},
   "source": [
    "import modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:10:17.132118Z",
     "start_time": "2024-08-21T16:10:11.080231Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "from utils.machine_learning import Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355c55299455b2da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:10:44.485004Z",
     "start_time": "2024-08-21T16:10:44.416351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerNum</th>\n",
       "      <th>Age</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>Destination</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>...</th>\n",
       "      <th>YesShoppingMall</th>\n",
       "      <th>YesSpa</th>\n",
       "      <th>YesVRDeck</th>\n",
       "      <th>YesTotalSpending</th>\n",
       "      <th>LogRoomService</th>\n",
       "      <th>LogFoodCourt</th>\n",
       "      <th>LogShoppingMall</th>\n",
       "      <th>LogSpa</th>\n",
       "      <th>LogVRDeck</th>\n",
       "      <th>LogTotalSpending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.700480</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>6.309918</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>6.602588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>8.182280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.812248</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>9.248021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.157735</td>\n",
       "      <td>5.918894</td>\n",
       "      <td>8.110728</td>\n",
       "      <td>5.267858</td>\n",
       "      <td>8.551981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.717028</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>5.023881</td>\n",
       "      <td>6.338594</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.995766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>01</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.827615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.404888</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>9.052165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>01</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.535297</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.535830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.956545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.869297</td>\n",
       "      <td>8.082093</td>\n",
       "      <td>8.442039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>02</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Europa</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>8.452975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>8.481980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerNum   Age HomePlanet    Destination CabinDeck CabinSide  \\\n",
       "0              01  39.0     Europa    TRAPPIST-1e         B         P   \n",
       "1              01  24.0      Earth    TRAPPIST-1e         F         S   \n",
       "2              01  58.0     Europa    TRAPPIST-1e         A         S   \n",
       "3              02  33.0     Europa    TRAPPIST-1e         A         S   \n",
       "4              01  16.0      Earth    TRAPPIST-1e         F         S   \n",
       "...           ...   ...        ...            ...       ...       ...   \n",
       "8688           01  41.0     Europa    55 Cancri e         A         P   \n",
       "8689           01  18.0      Earth  PSO J318.5-22         G         S   \n",
       "8690           01  26.0      Earth    TRAPPIST-1e         G         S   \n",
       "8691           01  32.0     Europa    55 Cancri e         E         S   \n",
       "8692           02  44.0     Europa    TRAPPIST-1e         E         S   \n",
       "\n",
       "     CryoSleep    VIP  RoomService  FoodCourt  ...  YesShoppingMall  YesSpa  \\\n",
       "0        False  False          0.0        0.0  ...            False   False   \n",
       "1        False  False        109.0        9.0  ...             True    True   \n",
       "2        False   True         43.0     3576.0  ...            False    True   \n",
       "3        False  False          0.0     1283.0  ...             True    True   \n",
       "4        False  False        303.0       70.0  ...             True    True   \n",
       "...        ...    ...          ...        ...  ...              ...     ...   \n",
       "8688     False   True          0.0     6819.0  ...            False    True   \n",
       "8689      True  False          0.0        0.0  ...            False   False   \n",
       "8690     False  False          0.0        0.0  ...             True    True   \n",
       "8691     False  False          0.0     1049.0  ...            False    True   \n",
       "8692     False  False        126.0     4688.0  ...            False   False   \n",
       "\n",
       "      YesVRDeck YesTotalSpending LogRoomService LogFoodCourt LogShoppingMall  \\\n",
       "0         False            False       0.000000     0.000000        0.000000   \n",
       "1          True             True       4.700480     2.302585        3.258097   \n",
       "2          True             True       3.784190     8.182280        0.000000   \n",
       "3          True             True       0.000000     7.157735        5.918894   \n",
       "4          True             True       5.717028     4.262680        5.023881   \n",
       "...         ...              ...            ...          ...             ...   \n",
       "8688       True             True       0.000000     8.827615        0.000000   \n",
       "8689      False            False       0.000000     0.000000        0.000000   \n",
       "8690      False             True       0.000000     0.000000        7.535297   \n",
       "8691       True             True       0.000000     6.956545        0.000000   \n",
       "8692       True             True       4.844187     8.452975        0.000000   \n",
       "\n",
       "        LogSpa LogVRDeck LogTotalSpending  \n",
       "0     0.000000  0.000000         0.000000  \n",
       "1     6.309918  3.806662         6.602588  \n",
       "2     8.812248  3.912023         9.248021  \n",
       "3     8.110728  5.267858         8.551981  \n",
       "4     6.338594  1.098612         6.995766  \n",
       "...        ...       ...              ...  \n",
       "8688  7.404888  4.317488         9.052165  \n",
       "8689  0.000000  0.000000         0.000000  \n",
       "8690  0.693147  0.000000         7.535830  \n",
       "8691  5.869297  8.082093         8.442039  \n",
       "8692  0.000000  2.564949         8.481980  \n",
       "\n",
       "[8693 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_pickle(\"../../data/train_processed.pkl\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e8183e337c4f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:10:45.621681Z",
     "start_time": "2024-08-21T16:10:45.597608Z"
    }
   },
   "outputs": [],
   "source": [
    "df = train_data.copy()\n",
    "X = df.drop(\n",
    "    columns=[\n",
    "        \"Transported\",\n",
    "        \"TotalSpending\",\n",
    "        \"LogRoomService\",\n",
    "        \"LogFoodCourt\",\n",
    "        \"LogShoppingMall\",\n",
    "        \"LogSpa\",\n",
    "        \"LogVRDeck\",\n",
    "        \"LogTotalSpending\",\n",
    "        \"LogTotalSpending\",\n",
    "    ]\n",
    ")\n",
    "y = df[\"Transported\"]\n",
    "numerical_columns = list(X.select_dtypes(include=\"number\").drop(columns=\"CabinBin\"))\n",
    "categorical_columns = list(X.select_dtypes(include=[\"object\"]))\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "cat_pipeline = Pipeline([(\"one_hot\", OneHotEncoder(sparse_output=False))])\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", IterativeImputer(random_state=0)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "ord_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"oe\", OrdinalEncoder()),\n",
    "        (\"imputer\", IterativeImputer(random_state=0)),\n",
    "        (\"rounder\", Rounder(decimals=0)),\n",
    "    ]\n",
    ")\n",
    "feature_preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"ord\", ord_pipeline, [\"CabinBin\"]),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664f702072970b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:10:47.051738Z",
     "start_time": "2024-08-21T16:10:46.845623Z"
    }
   },
   "outputs": [],
   "source": [
    "X_processed = feature_preprocessing.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d633f064459c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:10:56.031995Z",
     "start_time": "2024-08-21T16:10:47.802762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.296834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1511\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.295748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1511\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1511\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7823, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503643 -> initscore=0.014573\n",
      "[LightGBM] [Info] Start training from score 0.014573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1515\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3941, number of negative: 3883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503707 -> initscore=0.014826\n",
      "[LightGBM] [Info] Start training from score 0.014826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3940, number of negative: 3884\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 7824, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503579 -> initscore=0.014315\n",
      "[LightGBM] [Info] Start training from score 0.014315\n",
      "Accuracy: 0.805 (0.011)\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_processed, y, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaedb12736b6592",
   "metadata": {},
   "source": [
    "With no hyperparameter tuning we're almost at the best version of our autoML.\n",
    "\n",
    "Let's do some hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6b64890709e4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T03:08:20.806658Z",
     "start_time": "2024-08-19T03:05:48.259757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 23:12:51,754] A new study created in memory with name: no-name-d5f5c645-f1bd-4ea1-80e2-c2e15e05fc0d\n",
      "[I 2024-10-17 23:12:52,835] Trial 0 finished with value: 0.7839681416842742 and parameters: {'lambda_l1': 5.982141070874863e-06, 'lambda_l2': 0.9080277394315109, 'num_leaves': 70, 'feature_fraction': 0.4427644919082101, 'bagging_fraction': 0.7009305985832924, 'bagging_freq': 2, 'min_child_samples': 95, 'learning_rate': 0.4628930131688978, 'max_depth': 17}. Best is trial 0 with value: 0.7839681416842742.\n",
      "[I 2024-10-17 23:12:53,446] Trial 1 finished with value: 0.7867289442565499 and parameters: {'lambda_l1': 0.016928647280392558, 'lambda_l2': 7.802010453884022, 'num_leaves': 221, 'feature_fraction': 0.508415881215528, 'bagging_fraction': 0.481675594612943, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.672750632823794, 'max_depth': 5}. Best is trial 1 with value: 0.7867289442565499.\n",
      "[I 2024-10-17 23:12:54,264] Trial 2 finished with value: 0.7877626984279287 and parameters: {'lambda_l1': 0.0008170770832646326, 'lambda_l2': 0.13242623600943995, 'num_leaves': 73, 'feature_fraction': 0.44267142863165776, 'bagging_fraction': 0.4530488235048225, 'bagging_freq': 3, 'min_child_samples': 95, 'learning_rate': 0.42640930688855166, 'max_depth': 6}. Best is trial 2 with value: 0.7877626984279287.\n",
      "[I 2024-10-17 23:12:55,423] Trial 3 finished with value: 0.7992666049493413 and parameters: {'lambda_l1': 2.293062570738426e-05, 'lambda_l2': 3.1142415585286747e-06, 'num_leaves': 225, 'feature_fraction': 0.9022388539099977, 'bagging_fraction': 0.8897549568018599, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.16889199808974972, 'max_depth': 18}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:12:57,659] Trial 4 finished with value: 0.7746506563366247 and parameters: {'lambda_l1': 0.042671911302120766, 'lambda_l2': 2.149494268683597, 'num_leaves': 154, 'feature_fraction': 0.6298244926299077, 'bagging_fraction': 0.9755469524090845, 'bagging_freq': 4, 'min_child_samples': 77, 'learning_rate': 0.9790478164652062, 'max_depth': 13}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:12:59,296] Trial 5 finished with value: 0.7805157653797568 and parameters: {'lambda_l1': 0.14928261102456672, 'lambda_l2': 1.483276480618461e-07, 'num_leaves': 181, 'feature_fraction': 0.5284453940790739, 'bagging_fraction': 0.42527880472804636, 'bagging_freq': 7, 'min_child_samples': 100, 'learning_rate': 0.5019864026406248, 'max_depth': 20}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:13:01,871] Trial 6 finished with value: 0.770509485564697 and parameters: {'lambda_l1': 0.0005377723152702842, 'lambda_l2': 2.266519752862625e-08, 'num_leaves': 183, 'feature_fraction': 0.6308319153604753, 'bagging_fraction': 0.9428999027291343, 'bagging_freq': 1, 'min_child_samples': 90, 'learning_rate': 0.9264206974952097, 'max_depth': 11}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:13:03,585] Trial 7 finished with value: 0.7712000005293838 and parameters: {'lambda_l1': 0.005894031406455493, 'lambda_l2': 0.02038963199237774, 'num_leaves': 134, 'feature_fraction': 0.9441917121650846, 'bagging_fraction': 0.8164920872635135, 'bagging_freq': 2, 'min_child_samples': 69, 'learning_rate': 0.836423399516377, 'max_depth': 10}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:13:05,368] Trial 8 finished with value: 0.7847717462584146 and parameters: {'lambda_l1': 6.282928735060448e-08, 'lambda_l2': 4.472951207331887e-06, 'num_leaves': 193, 'feature_fraction': 0.7760542939557333, 'bagging_fraction': 0.6374445101121143, 'bagging_freq': 7, 'min_child_samples': 51, 'learning_rate': 0.30628768528179096, 'max_depth': 15}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:13:06,115] Trial 9 finished with value: 0.7699325895932414 and parameters: {'lambda_l1': 1.319130647177409e-06, 'lambda_l2': 0.149398377691894, 'num_leaves': 13, 'feature_fraction': 0.5963660266013384, 'bagging_fraction': 0.6924464949701405, 'bagging_freq': 3, 'min_child_samples': 14, 'learning_rate': 0.8042382972208917, 'max_depth': 11}. Best is trial 3 with value: 0.7992666049493413.\n",
      "[I 2024-10-17 23:13:10,698] Trial 10 finished with value: 0.7999565243572786 and parameters: {'lambda_l1': 1.385500975655134e-05, 'lambda_l2': 2.7827491679246613e-05, 'num_leaves': 248, 'feature_fraction': 0.9972626970333167, 'bagging_fraction': 0.8358709401495108, 'bagging_freq': 5, 'min_child_samples': 41, 'learning_rate': 0.029262163178356948, 'max_depth': 18}. Best is trial 10 with value: 0.7999565243572786.\n",
      "[I 2024-10-17 23:13:13,674] Trial 11 finished with value: 0.8024861847377334 and parameters: {'lambda_l1': 2.838170493628813e-06, 'lambda_l2': 5.5697217595562004e-05, 'num_leaves': 249, 'feature_fraction': 0.9999947653100535, 'bagging_fraction': 0.819493179597101, 'bagging_freq': 5, 'min_child_samples': 38, 'learning_rate': 0.029902138205438855, 'max_depth': 19}. Best is trial 11 with value: 0.8024861847377334.\n",
      "[I 2024-10-17 23:13:15,722] Trial 12 finished with value: 0.8001868724734333 and parameters: {'lambda_l1': 2.703485590237667e-08, 'lambda_l2': 0.00025026949051463527, 'num_leaves': 256, 'feature_fraction': 0.8536001592388927, 'bagging_fraction': 0.8119140798763248, 'bagging_freq': 5, 'min_child_samples': 34, 'learning_rate': 0.018666073545069606, 'max_depth': 20}. Best is trial 11 with value: 0.8024861847377334.\n",
      "[I 2024-10-17 23:13:21,097] Trial 13 finished with value: 0.8029465501051819 and parameters: {'lambda_l1': 1.2177854009561066e-08, 'lambda_l2': 0.00277117005316504, 'num_leaves': 249, 'feature_fraction': 0.8340981287365956, 'bagging_fraction': 0.7764195185621312, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.059665320688117654, 'max_depth': 20}. Best is trial 13 with value: 0.8029465501051819.\n",
      "[I 2024-10-17 23:13:24,052] Trial 14 finished with value: 0.7912139497919191 and parameters: {'lambda_l1': 3.876092767507905e-07, 'lambda_l2': 0.002994842677329113, 'num_leaves': 95, 'feature_fraction': 0.7675117229581264, 'bagging_fraction': 0.7307561368629008, 'bagging_freq': 6, 'min_child_samples': 16, 'learning_rate': 0.18912811252571168, 'max_depth': 15}. Best is trial 13 with value: 0.8029465501051819.\n",
      "[I 2024-10-17 23:13:24,954] Trial 15 finished with value: 0.8039832820603088 and parameters: {'lambda_l1': 5.299139977781451, 'lambda_l2': 0.00045759219951881726, 'num_leaves': 216, 'feature_fraction': 0.8209995478349912, 'bagging_fraction': 0.585252230055168, 'bagging_freq': 6, 'min_child_samples': 28, 'learning_rate': 0.18397640677174426, 'max_depth': 15}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:26,127] Trial 16 finished with value: 0.7940911506222575 and parameters: {'lambda_l1': 2.119978065428728, 'lambda_l2': 0.0028554761193430415, 'num_leaves': 207, 'feature_fraction': 0.8049517875689168, 'bagging_fraction': 0.5832560166176217, 'bagging_freq': 6, 'min_child_samples': 23, 'learning_rate': 0.23061876631030248, 'max_depth': 8}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:26,587] Trial 17 finished with value: 0.7986901721886908 and parameters: {'lambda_l1': 3.901108741229429, 'lambda_l2': 0.0018741472213441874, 'num_leaves': 160, 'feature_fraction': 0.7253218774689637, 'bagging_fraction': 0.5417500044484934, 'bagging_freq': 6, 'min_child_samples': 6, 'learning_rate': 0.3358804840830647, 'max_depth': 2}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:28,845] Trial 18 finished with value: 0.7937444704210124 and parameters: {'lambda_l1': 0.21055044880525806, 'lambda_l2': 0.00034106227159751254, 'num_leaves': 226, 'feature_fraction': 0.8714122482111815, 'bagging_fraction': 0.5984106486087203, 'bagging_freq': 7, 'min_child_samples': 28, 'learning_rate': 0.13095372231236127, 'max_depth': 15}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:31,012] Trial 19 finished with value: 0.7644119108703004 and parameters: {'lambda_l1': 0.00012056944599005037, 'lambda_l2': 0.02334154969227219, 'num_leaves': 111, 'feature_fraction': 0.6856561751562574, 'bagging_fraction': 0.526141308598125, 'bagging_freq': 6, 'min_child_samples': 50, 'learning_rate': 0.6637478474575764, 'max_depth': 16}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:31,998] Trial 20 finished with value: 0.7999563258383618 and parameters: {'lambda_l1': 1.4076559897569217e-07, 'lambda_l2': 2.677951510029394e-06, 'num_leaves': 11, 'feature_fraction': 0.816723729695981, 'bagging_fraction': 0.7369039130078332, 'bagging_freq': 4, 'min_child_samples': 59, 'learning_rate': 0.31908333665116795, 'max_depth': 13}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:34,775] Trial 21 finished with value: 0.8020270766567561 and parameters: {'lambda_l1': 1.6242561798769656e-08, 'lambda_l2': 6.219243859584934e-05, 'num_leaves': 245, 'feature_fraction': 0.9553320271516067, 'bagging_fraction': 0.787478788256973, 'bagging_freq': 6, 'min_child_samples': 40, 'learning_rate': 0.0787303560405658, 'max_depth': 20}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:37,135] Trial 22 finished with value: 0.7952397149003666 and parameters: {'lambda_l1': 2.299458858182347e-06, 'lambda_l2': 3.4881604224769895e-05, 'num_leaves': 235, 'feature_fraction': 0.9124687700239543, 'bagging_fraction': 0.8706242590426226, 'bagging_freq': 5, 'min_child_samples': 27, 'learning_rate': 0.11402477368856437, 'max_depth': 18}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:42,727] Trial 23 finished with value: 0.787072580501075 and parameters: {'lambda_l1': 5.121314305599272e-07, 'lambda_l2': 0.000585329113551869, 'num_leaves': 205, 'feature_fraction': 0.995630969028548, 'bagging_fraction': 0.648391570030642, 'bagging_freq': 4, 'min_child_samples': 40, 'learning_rate': 0.24308131044899983, 'max_depth': 18}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:47,771] Trial 24 finished with value: 0.7988058425440597 and parameters: {'lambda_l1': 8.160354423345458e-05, 'lambda_l2': 0.012329672762830948, 'num_leaves': 254, 'feature_fraction': 0.8436592938079082, 'bagging_fraction': 0.7599525461056288, 'bagging_freq': 7, 'min_child_samples': 17, 'learning_rate': 0.013835206063069323, 'max_depth': 13}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:50,325] Trial 25 finished with value: 0.7997255806843742 and parameters: {'lambda_l1': 1.0410868378118228e-08, 'lambda_l2': 9.962792447485432e-05, 'num_leaves': 208, 'feature_fraction': 0.7530425536920982, 'bagging_fraction': 0.894465526801504, 'bagging_freq': 6, 'min_child_samples': 34, 'learning_rate': 0.0963883361179717, 'max_depth': 19}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:52,914] Trial 26 finished with value: 0.7606176849915066 and parameters: {'lambda_l1': 0.003936512291834665, 'lambda_l2': 4.785087531009591e-07, 'num_leaves': 174, 'feature_fraction': 0.68180639280388, 'bagging_fraction': 0.6614972414906919, 'bagging_freq': 4, 'min_child_samples': 6, 'learning_rate': 0.38988649846822576, 'max_depth': 16}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:55,458] Trial 27 finished with value: 0.7869577042213723 and parameters: {'lambda_l1': 9.648594773677077e-08, 'lambda_l2': 8.452818502049368e-06, 'num_leaves': 231, 'feature_fraction': 0.8980767617293748, 'bagging_fraction': 0.6060160909253882, 'bagging_freq': 5, 'min_child_samples': 59, 'learning_rate': 0.2478701965192716, 'max_depth': 17}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:58,142] Trial 28 finished with value: 0.7734984525450456 and parameters: {'lambda_l1': 3.673450018370047e-05, 'lambda_l2': 0.0018325236412334172, 'num_leaves': 210, 'feature_fraction': 0.9482209469175182, 'bagging_fraction': 0.8572082989552845, 'bagging_freq': 7, 'min_child_samples': 45, 'learning_rate': 0.6067719475060346, 'max_depth': 14}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:13:59,698] Trial 29 finished with value: 0.7992664064304247 and parameters: {'lambda_l1': 8.312619153614896e-06, 'lambda_l2': 0.2012264555633377, 'num_leaves': 31, 'feature_fraction': 0.8174663132443288, 'bagging_fraction': 0.6944818198129357, 'bagging_freq': 6, 'min_child_samples': 32, 'learning_rate': 0.1834772179831044, 'max_depth': 17}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:14:02,466] Trial 30 finished with value: 0.803522122617194 and parameters: {'lambda_l1': 0.8249178361681947, 'lambda_l2': 8.220907200336732e-07, 'num_leaves': 150, 'feature_fraction': 0.8757316249762033, 'bagging_fraction': 0.7826638863977564, 'bagging_freq': 3, 'min_child_samples': 23, 'learning_rate': 0.07006700795472026, 'max_depth': 19}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:14:04,186] Trial 31 finished with value: 0.8021416220715979 and parameters: {'lambda_l1': 0.9465837667017326, 'lambda_l2': 3.5758667111214754e-07, 'num_leaves': 146, 'feature_fraction': 0.8697479706266661, 'bagging_fraction': 0.77372198474243, 'bagging_freq': 3, 'min_child_samples': 23, 'learning_rate': 0.08147021988486618, 'max_depth': 19}. Best is trial 15 with value: 0.8039832820603088.\n",
      "[I 2024-10-17 23:14:05,202] Trial 32 finished with value: 0.8074335408297164 and parameters: {'lambda_l1': 9.491148511715021, 'lambda_l2': 1.604404937631013e-08, 'num_leaves': 118, 'feature_fraction': 0.9191598295606791, 'bagging_fraction': 0.730228902545114, 'bagging_freq': 2, 'min_child_samples': 22, 'learning_rate': 0.14228155266790352, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:06,165] Trial 33 finished with value: 0.8043282417642773 and parameters: {'lambda_l1': 9.622752104789086, 'lambda_l2': 1.3881814184913607e-08, 'num_leaves': 101, 'feature_fraction': 0.9202174052549912, 'bagging_fraction': 0.7180695815643338, 'bagging_freq': 2, 'min_child_samples': 13, 'learning_rate': 0.14969692969719228, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:07,909] Trial 34 finished with value: 0.8059380978314457 and parameters: {'lambda_l1': 8.25296985279137, 'lambda_l2': 1.3344534620727254e-08, 'num_leaves': 73, 'feature_fraction': 0.9194927668295747, 'bagging_fraction': 0.7180101662745716, 'bagging_freq': 2, 'min_child_samples': 11, 'learning_rate': 0.14503729712896707, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:09,751] Trial 35 finished with value: 0.8063979999880889 and parameters: {'lambda_l1': 4.620675892678905, 'lambda_l2': 1.0254259463634423e-08, 'num_leaves': 58, 'feature_fraction': 0.9314611777529115, 'bagging_fraction': 0.7231791523530663, 'bagging_freq': 1, 'min_child_samples': 11, 'learning_rate': 0.15299272513992324, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:10,429] Trial 36 finished with value: 0.8007619156016679 and parameters: {'lambda_l1': 8.28109252457278, 'lambda_l2': 1.0026731862951934e-08, 'num_leaves': 56, 'feature_fraction': 0.4040783026204495, 'bagging_fraction': 0.7195833761003664, 'bagging_freq': 1, 'min_child_samples': 11, 'learning_rate': 0.4091368305690819, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:12,121] Trial 37 finished with value: 0.7912132880621974 and parameters: {'lambda_l1': 0.256923032024163, 'lambda_l2': 6.47463474337139e-08, 'num_leaves': 75, 'feature_fraction': 0.9212784663592951, 'bagging_fraction': 0.6866869510968633, 'bagging_freq': 2, 'min_child_samples': 11, 'learning_rate': 0.27774372233422856, 'max_depth': 12}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:13,750] Trial 38 finished with value: 0.7829302186156482 and parameters: {'lambda_l1': 0.06587527573278915, 'lambda_l2': 5.731167423070888e-08, 'num_leaves': 92, 'feature_fraction': 0.9625420100932005, 'bagging_fraction': 0.738029578702912, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 0.47103284644229143, 'max_depth': 9}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:14,996] Trial 39 finished with value: 0.7805156992067847 and parameters: {'lambda_l1': 0.655333241060497, 'lambda_l2': 1.344393104257467e-08, 'num_leaves': 47, 'feature_fraction': 0.9249709036068653, 'bagging_fraction': 0.6717689084193746, 'bagging_freq': 2, 'min_child_samples': 10, 'learning_rate': 0.555970003073623, 'max_depth': 14}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:16,488] Trial 40 finished with value: 0.7994956957790246 and parameters: {'lambda_l1': 1.7320975822405207, 'lambda_l2': 5.106481461443459e-08, 'num_leaves': 117, 'feature_fraction': 0.5113225822974375, 'bagging_fraction': 0.9213756997980918, 'bagging_freq': 2, 'min_child_samples': 5, 'learning_rate': 0.1448285179179803, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:17,330] Trial 41 finished with value: 0.8034067169537138 and parameters: {'lambda_l1': 8.58369780447179, 'lambda_l2': 2.9334942738400805e-08, 'num_leaves': 92, 'feature_fraction': 0.9018771529872933, 'bagging_fraction': 0.4991252866838567, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 0.1962975465774527, 'max_depth': 14}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:18,691] Trial 42 finished with value: 0.8051323095492231 and parameters: {'lambda_l1': 3.601063756952101, 'lambda_l2': 7.301830909660156e-08, 'num_leaves': 112, 'feature_fraction': 0.9623612097578318, 'bagging_fraction': 0.6240099711921147, 'bagging_freq': 1, 'min_child_samples': 12, 'learning_rate': 0.13898330141342413, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:23,847] Trial 43 finished with value: 0.7938593467007149 and parameters: {'lambda_l1': 2.7498675399274513, 'lambda_l2': 1.6833782021807214e-07, 'num_leaves': 77, 'feature_fraction': 0.9628624653259862, 'bagging_fraction': 0.6362145913883032, 'bagging_freq': 1, 'min_child_samples': 13, 'learning_rate': 0.36318456125210985, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:29,457] Trial 44 finished with value: 0.7902930205381054 and parameters: {'lambda_l1': 0.024885928163137658, 'lambda_l2': 1.4872586356810202e-07, 'num_leaves': 122, 'feature_fraction': 0.9732358761340749, 'bagging_fraction': 0.7175903237160477, 'bagging_freq': 2, 'min_child_samples': 9, 'learning_rate': 0.15020792688729628, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:31,357] Trial 45 finished with value: 0.7851167721353555 and parameters: {'lambda_l1': 0.37815157699913016, 'lambda_l2': 2.0600856035130788e-08, 'num_leaves': 101, 'feature_fraction': 0.9325564305587992, 'bagging_fraction': 0.6279781930240496, 'bagging_freq': 2, 'min_child_samples': 19, 'learning_rate': 0.2866692019680608, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:33,856] Trial 46 finished with value: 0.78615191593915 and parameters: {'lambda_l1': 0.08235759906443008, 'lambda_l2': 1.3579404814491777e-06, 'num_leaves': 81, 'feature_fraction': 0.8880209216993049, 'bagging_fraction': 0.563133558801138, 'bagging_freq': 1, 'min_child_samples': 15, 'learning_rate': 0.22861190937235898, 'max_depth': 12}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:35,399] Trial 47 finished with value: 0.8026021859579628 and parameters: {'lambda_l1': 1.268396028564483, 'lambda_l2': 9.441658467977187e-08, 'num_leaves': 56, 'feature_fraction': 0.5775275338173373, 'bagging_fraction': 0.7051727755062495, 'bagging_freq': 3, 'min_child_samples': 5, 'learning_rate': 0.1309153523322874, 'max_depth': 5}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:36,952] Trial 48 finished with value: 0.805707882061235 and parameters: {'lambda_l1': 4.199756608382723, 'lambda_l2': 3.0145873970126576e-07, 'num_leaves': 137, 'feature_fraction': 0.972793361354605, 'bagging_fraction': 0.7488222265865784, 'bagging_freq': 1, 'min_child_samples': 79, 'learning_rate': 0.2021129045865846, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:41,878] Trial 49 finished with value: 0.7977710957780982 and parameters: {'lambda_l1': 3.377556069498806, 'lambda_l2': 3.387860921467988e-07, 'num_leaves': 37, 'feature_fraction': 0.9733659590398238, 'bagging_fraction': 0.8014838740370825, 'bagging_freq': 1, 'min_child_samples': 72, 'learning_rate': 0.20768947845503805, 'max_depth': 12}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:44,684] Trial 50 finished with value: 0.7733845026869535 and parameters: {'lambda_l1': 0.008775005316094726, 'lambda_l2': 3.386717551394694e-08, 'num_leaves': 134, 'feature_fraction': 0.9852067587005737, 'bagging_fraction': 0.7536166719984582, 'bagging_freq': 1, 'min_child_samples': 94, 'learning_rate': 0.7721759519549032, 'max_depth': 14}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:45,891] Trial 51 finished with value: 0.8029471456619316 and parameters: {'lambda_l1': 9.015263772123946, 'lambda_l2': 1.3145856478168242e-08, 'num_leaves': 103, 'feature_fraction': 0.9359363442580327, 'bagging_fraction': 0.6859977709032397, 'bagging_freq': 2, 'min_child_samples': 79, 'learning_rate': 0.15165838861882203, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:48,935] Trial 52 finished with value: 0.7977703678754042 and parameters: {'lambda_l1': 3.654244537563486, 'lambda_l2': 1.5788657029070644e-07, 'num_leaves': 129, 'feature_fraction': 0.8584700110115282, 'bagging_fraction': 0.6591419057483541, 'bagging_freq': 1, 'min_child_samples': 14, 'learning_rate': 0.2661753509659944, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:50,082] Trial 53 finished with value: 0.8061679165638228 and parameters: {'lambda_l1': 0.49987534923279214, 'lambda_l2': 2.8082702730569055e-08, 'num_leaves': 62, 'feature_fraction': 0.9070761827161301, 'bagging_fraction': 0.7557811707569468, 'bagging_freq': 2, 'min_child_samples': 79, 'learning_rate': 0.04922977151122977, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:51,275] Trial 54 finished with value: 0.8023718378418081 and parameters: {'lambda_l1': 0.49922267491070266, 'lambda_l2': 6.665595022911199e-08, 'num_leaves': 66, 'feature_fraction': 0.78957472538104, 'bagging_fraction': 0.7555881658561988, 'bagging_freq': 2, 'min_child_samples': 81, 'learning_rate': 0.041538633898146174, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:52,545] Trial 55 finished with value: 0.8019119356851648 and parameters: {'lambda_l1': 1.514360947595665, 'lambda_l2': 3.33452093052603e-08, 'num_leaves': 63, 'feature_fraction': 0.8947231536094831, 'bagging_fraction': 0.8331281944659398, 'bagging_freq': 1, 'min_child_samples': 85, 'learning_rate': 0.09928941391202507, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:53,034] Trial 56 finished with value: 0.7820106789942503 and parameters: {'lambda_l1': 0.09737973738840584, 'lambda_l2': 1.215184062264237e-06, 'num_leaves': 168, 'feature_fraction': 0.9455484037063835, 'bagging_fraction': 0.9847369713374294, 'bagging_freq': 3, 'min_child_samples': 66, 'learning_rate': 0.05006370100447689, 'max_depth': 2}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:56,846] Trial 57 finished with value: 0.7988055116791987 and parameters: {'lambda_l1': 0.0012360157634982631, 'lambda_l2': 9.8568408501082e-06, 'num_leaves': 87, 'feature_fraction': 0.9831998798235051, 'bagging_fraction': 0.6245576589330335, 'bagging_freq': 2, 'min_child_samples': 74, 'learning_rate': 0.17999757817790324, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:14:59,127] Trial 58 finished with value: 0.8035226520009715 and parameters: {'lambda_l1': 4.278624193502201, 'lambda_l2': 1.703081025973912e-07, 'num_leaves': 40, 'feature_fraction': 0.8512385862459259, 'bagging_fraction': 0.7378000538925727, 'bagging_freq': 1, 'min_child_samples': 63, 'learning_rate': 0.10243282192123758, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:01,228] Trial 59 finished with value: 0.8000720623667028 and parameters: {'lambda_l1': 0.2869724117365581, 'lambda_l2': 2.7271247674650757e-08, 'num_leaves': 20, 'feature_fraction': 0.9469073093356118, 'bagging_fraction': 0.8023218128546084, 'bagging_freq': 1, 'min_child_samples': 92, 'learning_rate': 0.22244695571284956, 'max_depth': 20}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:02,368] Trial 60 finished with value: 0.80352291669286 and parameters: {'lambda_l1': 2.0495013390093155, 'lambda_l2': 3.430638100161267e-07, 'num_leaves': 142, 'feature_fraction': 0.8809190530370514, 'bagging_fraction': 0.7615025238855954, 'bagging_freq': 3, 'min_child_samples': 87, 'learning_rate': 0.11957543581917797, 'max_depth': 13}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:03,413] Trial 61 finished with value: 0.79236469777811 and parameters: {'lambda_l1': 9.798464660627767, 'lambda_l2': 1.0065298498335394e-08, 'num_leaves': 109, 'feature_fraction': 0.913632793674796, 'bagging_fraction': 0.708933175141934, 'bagging_freq': 2, 'min_child_samples': 83, 'learning_rate': 0.010640476605600108, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:04,374] Trial 62 finished with value: 0.8028333281497838 and parameters: {'lambda_l1': 4.748117303619651, 'lambda_l2': 2.0564728120558214e-08, 'num_leaves': 127, 'feature_fraction': 0.9998003292893406, 'bagging_fraction': 0.684466278765881, 'bagging_freq': 2, 'min_child_samples': 100, 'learning_rate': 0.16501496464429222, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:07,252] Trial 63 finished with value: 0.8015667774622799 and parameters: {'lambda_l1': 1.249369666584003, 'lambda_l2': 1.0005383161992941e-07, 'num_leaves': 113, 'feature_fraction': 0.9166666072898056, 'bagging_fraction': 0.7279080668200375, 'bagging_freq': 2, 'min_child_samples': 9, 'learning_rate': 0.06039681740992964, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:11,861] Trial 64 finished with value: 0.7948952184072033 and parameters: {'lambda_l1': 0.1456841836333727, 'lambda_l2': 2.0556344982198858e-08, 'num_leaves': 104, 'feature_fraction': 0.9615027899363494, 'bagging_fraction': 0.7423879757180953, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.1177898549009114, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:14,895] Trial 65 finished with value: 0.801566843635252 and parameters: {'lambda_l1': 5.1885506437751205, 'lambda_l2': 4.826069039914003e-08, 'num_leaves': 83, 'feature_fraction': 0.9272767773475777, 'bagging_fraction': 0.7909592828223656, 'bagging_freq': 3, 'min_child_samples': 17, 'learning_rate': 0.3376267245114802, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:17,344] Trial 66 finished with value: 0.6974654428196038 and parameters: {'lambda_l1': 0.649129304145663, 'lambda_l2': 5.820660454955227e-07, 'num_leaves': 56, 'feature_fraction': 0.9007797838489037, 'bagging_fraction': 0.4206047515476364, 'bagging_freq': 2, 'min_child_samples': 30, 'learning_rate': 0.9836500892376372, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:18,337] Trial 67 finished with value: 0.8027175254484706 and parameters: {'lambda_l1': 2.3485701929450458, 'lambda_l2': 5.5292802236925915, 'num_leaves': 139, 'feature_fraction': 0.8319199063959545, 'bagging_fraction': 0.6749450022630114, 'bagging_freq': 1, 'min_child_samples': 77, 'learning_rate': 0.16644284518264657, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:19,722] Trial 68 finished with value: 0.8034072463374914 and parameters: {'lambda_l1': 6.4089040963657755, 'lambda_l2': 9.355266350915111e-08, 'num_leaves': 158, 'feature_fraction': 0.9404591349361409, 'bagging_fraction': 0.8222011588608822, 'bagging_freq': 2, 'min_child_samples': 25, 'learning_rate': 0.20685047779231763, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:21,113] Trial 69 finished with value: 0.8054776001180526 and parameters: {'lambda_l1': 2.4768234462461414, 'lambda_l2': 1.4624346869441512e-08, 'num_leaves': 121, 'feature_fraction': 0.8726693199654041, 'bagging_fraction': 0.7069054333783911, 'bagging_freq': 1, 'min_child_samples': 54, 'learning_rate': 0.07485429488437881, 'max_depth': 7}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:22,745] Trial 70 finished with value: 0.8030634115740499 and parameters: {'lambda_l1': 0.497219087584474, 'lambda_l2': 2.3625322889223976e-07, 'num_leaves': 25, 'feature_fraction': 0.7335595011198806, 'bagging_fraction': 0.6083177684208283, 'bagging_freq': 1, 'min_child_samples': 54, 'learning_rate': 0.08060500260280729, 'max_depth': 6}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:24,517] Trial 71 finished with value: 0.80386761170494 and parameters: {'lambda_l1': 2.3722558892058307, 'lambda_l2': 1.0249775710566727e-08, 'num_leaves': 122, 'feature_fraction': 0.8711277967848243, 'bagging_fraction': 0.7057755725038577, 'bagging_freq': 1, 'min_child_samples': 8, 'learning_rate': 0.04434638601136785, 'max_depth': 7}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:26,650] Trial 72 finished with value: 0.8000710697721202 and parameters: {'lambda_l1': 1.1510905698351614, 'lambda_l2': 1.9063038798123292e-08, 'num_leaves': 69, 'feature_fraction': 0.9769359686101042, 'bagging_fraction': 0.6484969340451672, 'bagging_freq': 1, 'min_child_samples': 45, 'learning_rate': 0.13356711472088773, 'max_depth': 10}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:28,570] Trial 73 finished with value: 0.8050184258641032 and parameters: {'lambda_l1': 5.341270356311559, 'lambda_l2': 3.806648186237163e-08, 'num_leaves': 97, 'feature_fraction': 0.9096366060230766, 'bagging_fraction': 0.7719801538818005, 'bagging_freq': 2, 'min_child_samples': 68, 'learning_rate': 0.08627407562385635, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:29,379] Trial 74 finished with value: 0.7975413432186931 and parameters: {'lambda_l1': 4.482816849710315, 'lambda_l2': 4.157533385802879e-08, 'num_leaves': 95, 'feature_fraction': 0.8849242413283929, 'bagging_fraction': 0.7556342668122268, 'bagging_freq': 1, 'min_child_samples': 70, 'learning_rate': 0.09269863376238704, 'max_depth': 3}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:31,633] Trial 75 finished with value: 0.8040974966102896 and parameters: {'lambda_l1': 0.9491659051632466, 'lambda_l2': 8.147134690264865e-08, 'num_leaves': 48, 'feature_fraction': 0.9090658098618144, 'bagging_fraction': 0.7737641248750672, 'bagging_freq': 3, 'min_child_samples': 65, 'learning_rate': 0.06571957077281695, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:33,108] Trial 76 finished with value: 0.7717733893333139 and parameters: {'lambda_l1': 0.1738272241428978, 'lambda_l2': 4.0988183216723833e-08, 'num_leaves': 116, 'feature_fraction': 0.9600301932447259, 'bagging_fraction': 0.8495401318613797, 'bagging_freq': 2, 'min_child_samples': 55, 'learning_rate': 0.9377142520039665, 'max_depth': 14}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:33,991] Trial 77 finished with value: 0.8012222147961443 and parameters: {'lambda_l1': 2.618549423008613, 'lambda_l2': 2.6274651738959576e-06, 'num_leaves': 135, 'feature_fraction': 0.8603079866122462, 'bagging_fraction': 0.7765903055303987, 'bagging_freq': 1, 'min_child_samples': 74, 'learning_rate': 0.034947816220519165, 'max_depth': 8}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:35,679] Trial 78 finished with value: 0.7968508944269785 and parameters: {'lambda_l1': 1.6782541895476395, 'lambda_l2': 2.4696447376200837e-07, 'num_leaves': 73, 'feature_fraction': 0.936695242057558, 'bagging_fraction': 0.7270465388766864, 'bagging_freq': 2, 'min_child_samples': 49, 'learning_rate': 0.2449487938538953, 'max_depth': 11}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:36,578] Trial 79 finished with value: 0.804097695129206 and parameters: {'lambda_l1': 6.218319741561299, 'lambda_l2': 1.988639180975655e-08, 'num_leaves': 86, 'feature_fraction': 0.8371815712607218, 'bagging_fraction': 0.6718515338297826, 'bagging_freq': 1, 'min_child_samples': 61, 'learning_rate': 0.11055074786692073, 'max_depth': 14}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:38,144] Trial 80 finished with value: 0.794665002636993 and parameters: {'lambda_l1': 0.40174071231872793, 'lambda_l2': 1.059766353061499e-07, 'num_leaves': 107, 'feature_fraction': 0.4730764357156841, 'bagging_fraction': 0.45689124574028206, 'bagging_freq': 2, 'min_child_samples': 79, 'learning_rate': 0.18160697188346664, 'max_depth': 13}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:39,863] Trial 81 finished with value: 0.8030623528064951 and parameters: {'lambda_l1': 9.665501142007498, 'lambda_l2': 1.4177963394113488e-08, 'num_leaves': 98, 'feature_fraction': 0.6441099243960329, 'bagging_fraction': 0.716853517815402, 'bagging_freq': 2, 'min_child_samples': 12, 'learning_rate': 0.15310202286566693, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:41,266] Trial 82 finished with value: 0.8036368665509522 and parameters: {'lambda_l1': 3.206588398447372, 'lambda_l2': 4.6262907961897354e-08, 'num_leaves': 119, 'feature_fraction': 0.9270489519705856, 'bagging_fraction': 0.6968976647231252, 'bagging_freq': 2, 'min_child_samples': 16, 'learning_rate': 0.08043451845272553, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:42,276] Trial 83 finished with value: 0.8057086761369014 and parameters: {'lambda_l1': 5.181026021626324, 'lambda_l2': 2.657126550664677e-08, 'num_leaves': 60, 'feature_fraction': 0.9034082000687901, 'bagging_fraction': 0.7467522132163709, 'bagging_freq': 3, 'min_child_samples': 68, 'learning_rate': 0.13379160387413977, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:43,534] Trial 84 finished with value: 0.7945495308005408 and parameters: {'lambda_l1': 0.7686787340037349, 'lambda_l2': 2.465548628083925e-08, 'num_leaves': 62, 'feature_fraction': 0.8948276924178806, 'bagging_fraction': 0.7925444821249192, 'bagging_freq': 3, 'min_child_samples': 68, 'learning_rate': 0.2082348661836787, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:44,580] Trial 85 finished with value: 0.803523247557721 and parameters: {'lambda_l1': 5.376906190080975, 'lambda_l2': 6.585194228634942e-08, 'num_leaves': 43, 'feature_fraction': 0.9579561246076648, 'bagging_fraction': 0.7437311849168455, 'bagging_freq': 4, 'min_child_samples': 57, 'learning_rate': 0.1308937958870003, 'max_depth': 4}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:46,880] Trial 86 finished with value: 0.7985767517143763 and parameters: {'lambda_l1': 1.4906317234102082, 'lambda_l2': 3.3571609977477817e-08, 'num_leaves': 79, 'feature_fraction': 0.9070107078471028, 'bagging_fraction': 0.7673714439094558, 'bagging_freq': 3, 'min_child_samples': 75, 'learning_rate': 0.023382275453692078, 'max_depth': 15}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:48,020] Trial 87 finished with value: 0.7981161878280112 and parameters: {'lambda_l1': 3.2673493382519156, 'lambda_l2': 1.3240727499800507e-07, 'num_leaves': 53, 'feature_fraction': 0.9856641410750674, 'bagging_fraction': 0.7465537563524465, 'bagging_freq': 1, 'min_child_samples': 88, 'learning_rate': 0.29203778656055923, 'max_depth': 17}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:49,432] Trial 88 finished with value: 0.8051327727600283 and parameters: {'lambda_l1': 5.622721557494865, 'lambda_l2': 1.558047283879347e-08, 'num_leaves': 128, 'feature_fraction': 0.8075439279226828, 'bagging_fraction': 0.8156050716575488, 'bagging_freq': 1, 'min_child_samples': 67, 'learning_rate': 0.25847828746164436, 'max_depth': 20}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:51,510] Trial 89 finished with value: 0.7846573331895174 and parameters: {'lambda_l1': 0.000315963139563684, 'lambda_l2': 1.4252877038629402e-08, 'num_leaves': 153, 'feature_fraction': 0.7985297920097915, 'bagging_fraction': 0.8181050820348962, 'bagging_freq': 1, 'min_child_samples': 36, 'learning_rate': 0.3159847801856771, 'max_depth': 20}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:52,609] Trial 90 finished with value: 0.7962757851257717 and parameters: {'lambda_l1': 1.8348760650361595, 'lambda_l2': 1.0287804276839272e-08, 'num_leaves': 128, 'feature_fraction': 0.7758841006456841, 'bagging_fraction': 0.8028658683288137, 'bagging_freq': 1, 'min_child_samples': 60, 'learning_rate': 0.24622514436638454, 'max_depth': 20}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:53,382] Trial 91 finished with value: 0.8061677842178785 and parameters: {'lambda_l1': 6.12300671463523, 'lambda_l2': 2.8644497003897574e-08, 'num_leaves': 132, 'feature_fraction': 0.8656128094869793, 'bagging_fraction': 0.724226416179399, 'bagging_freq': 1, 'min_child_samples': 68, 'learning_rate': 0.17845720590892822, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:54,220] Trial 92 finished with value: 0.8037521398684879 and parameters: {'lambda_l1': 9.986114766198996, 'lambda_l2': 1.9908319102423093e-08, 'num_leaves': 143, 'feature_fraction': 0.8686657284853434, 'bagging_fraction': 0.8858277943982172, 'bagging_freq': 1, 'min_child_samples': 72, 'learning_rate': 0.18522204478580503, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:55,486] Trial 93 finished with value: 0.8013372234217911 and parameters: {'lambda_l1': 3.139609020274429, 'lambda_l2': 5.903045188120658e-08, 'num_leaves': 125, 'feature_fraction': 0.8476994641898434, 'bagging_fraction': 0.729906460632533, 'bagging_freq': 1, 'min_child_samples': 64, 'learning_rate': 0.22129429927020045, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:56,627] Trial 94 finished with value: 0.8045581266696267 and parameters: {'lambda_l1': 6.321675296635242, 'lambda_l2': 2.3820998774461887e-07, 'num_leaves': 132, 'feature_fraction': 0.8156873859074429, 'bagging_fraction': 0.693693430804627, 'bagging_freq': 1, 'min_child_samples': 82, 'learning_rate': 0.15611007602803725, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:15:59,260] Trial 95 finished with value: 0.8004158309571723 and parameters: {'lambda_l1': 0.7616942107693074, 'lambda_l2': 3.045580046034912e-08, 'num_leaves': 164, 'feature_fraction': 0.947937271546814, 'bagging_fraction': 0.7108502269192117, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.11527214156171652, 'max_depth': 20}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:16:01,182] Trial 96 finished with value: 0.8006471716679096 and parameters: {'lambda_l1': 2.2047797213358455, 'lambda_l2': 1.6069325531163033e-08, 'num_leaves': 188, 'feature_fraction': 0.881507467215365, 'bagging_fraction': 0.6500555072343814, 'bagging_freq': 1, 'min_child_samples': 78, 'learning_rate': 0.19372617996978497, 'max_depth': 19}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:16:03,281] Trial 97 finished with value: 0.7927085987145238 and parameters: {'lambda_l1': 1.0537365406402277, 'lambda_l2': 2.6286565770579025e-08, 'num_leaves': 149, 'feature_fraction': 0.9711135608297645, 'bagging_fraction': 0.6756728965024028, 'bagging_freq': 1, 'min_child_samples': 67, 'learning_rate': 0.2708478261592688, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:16:04,204] Trial 98 finished with value: 0.789257942907283 and parameters: {'lambda_l1': 3.971288682641781, 'lambda_l2': 0.26564153401808466, 'num_leaves': 137, 'feature_fraction': 0.9245726006898176, 'bagging_fraction': 0.7233478013908818, 'bagging_freq': 1, 'min_child_samples': 71, 'learning_rate': 0.7403434203199953, 'max_depth': 18}. Best is trial 32 with value: 0.8074335408297164.\n",
      "[I 2024-10-17 23:16:06,848] Trial 99 finished with value: 0.7994957619519967 and parameters: {'lambda_l1': 0.03567001690277196, 'lambda_l2': 7.202883517109694e-08, 'num_leaves': 114, 'feature_fraction': 0.8614881246895927, 'bagging_fraction': 0.7526450813310761, 'bagging_freq': 1, 'min_child_samples': 7, 'learning_rate': 0.059228777722501215, 'max_depth': 16}. Best is trial 32 with value: 0.8074335408297164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8074335408297164\n",
      "Best hyperparameters: {'lambda_l1': 9.491148511715021, 'lambda_l2': 1.604404937631013e-08, 'num_leaves': 118, 'feature_fraction': 0.9191598295606791, 'bagging_fraction': 0.730228902545114, 'bagging_freq': 2, 'min_child_samples': 22, 'learning_rate': 0.14228155266790352, 'max_depth': 19}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, data=X_processed, target=y):\n",
    "    data = data.copy()\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1.0),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**param)\n",
    "    return cross_val_score(\n",
    "        model, data, target, scoring=\"accuracy\", n_jobs=-1, cv=5\n",
    "    ).mean()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Accuracy: {}\".format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe4f2277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 9.491148511715021,\n",
       " 'lambda_l2': 1.604404937631013e-08,\n",
       " 'num_leaves': 118,\n",
       " 'feature_fraction': 0.9191598295606791,\n",
       " 'bagging_fraction': 0.730228902545114,\n",
       " 'bagging_freq': 2,\n",
       " 'min_child_samples': 22,\n",
       " 'learning_rate': 0.14228155266790352,\n",
       " 'max_depth': 19}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a652e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b6b5b2fb00e961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:11:01.815965Z",
     "start_time": "2024-08-21T16:11:01.812667Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm_pipeline = Pipeline(\n",
    "    steps=[(\"preprocessor\", feature_preprocessing), (\"model\", model)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298673de0f84802f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:11:05.358615Z",
     "start_time": "2024-08-21T16:11:03.015036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1514\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1506\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 66\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1512\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 66\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8055926087436995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "cross_val_score(\n",
    "    lgbm_pipeline, X, y, scoring=\"accuracy\", n_jobs=-1, cv=5, error_score=\"raise\"\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc20204b4896a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:11:06.845475Z",
     "start_time": "2024-08-21T16:11:06.026348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                                   OneHotEncoder(sparse_output=False))]),\n",
       "                                                  [&#x27;PassengerNum&#x27;, &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;, &#x27;CabinDeck&#x27;,\n",
       "                                                   &#x27;CabinSide&#x27;, &#x27;CryoSleep&#x27;,\n",
       "                                                   &#x27;VIP&#x27;, &#x27;NameMissing&#x27;,\n",
       "                                                   &#x27;HomeMissing&#x27;,\n",
       "                                                   &#x27;DestinationMissing&#x27;,\n",
       "                                                   &#x27;CabinMissing&#x27;,\n",
       "                                                   &#x27;CryoMissing&#x27;, &#x27;VIPMissing&#x27;,\n",
       "                                                   &#x27;FamilyGroupMember&#x27;,\n",
       "                                                   &#x27;YesRoomService&#x27;,\n",
       "                                                   &#x27;...\n",
       "                                                                   IterativeImputer(random_state=0)),\n",
       "                                                                  (&#x27;rounder&#x27;,\n",
       "                                                                   Rounder())]),\n",
       "                                                  [&#x27;CabinBin&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=0.730228902545114,\n",
       "                                bagging_freq=2,\n",
       "                                feature_fraction=0.9191598295606791,\n",
       "                                lambda_l1=9.491148511715021,\n",
       "                                lambda_l2=1.604404937631013e-08,\n",
       "                                learning_rate=0.14228155266790352, max_depth=19,\n",
       "                                min_child_samples=22, num_leaves=118))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                                   OneHotEncoder(sparse_output=False))]),\n",
       "                                                  [&#x27;PassengerNum&#x27;, &#x27;HomePlanet&#x27;,\n",
       "                                                   &#x27;Destination&#x27;, &#x27;CabinDeck&#x27;,\n",
       "                                                   &#x27;CabinSide&#x27;, &#x27;CryoSleep&#x27;,\n",
       "                                                   &#x27;VIP&#x27;, &#x27;NameMissing&#x27;,\n",
       "                                                   &#x27;HomeMissing&#x27;,\n",
       "                                                   &#x27;DestinationMissing&#x27;,\n",
       "                                                   &#x27;CabinMissing&#x27;,\n",
       "                                                   &#x27;CryoMissing&#x27;, &#x27;VIPMissing&#x27;,\n",
       "                                                   &#x27;FamilyGroupMember&#x27;,\n",
       "                                                   &#x27;YesRoomService&#x27;,\n",
       "                                                   &#x27;...\n",
       "                                                                   IterativeImputer(random_state=0)),\n",
       "                                                                  (&#x27;rounder&#x27;,\n",
       "                                                                   Rounder())]),\n",
       "                                                  [&#x27;CabinBin&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=0.730228902545114,\n",
       "                                bagging_freq=2,\n",
       "                                feature_fraction=0.9191598295606791,\n",
       "                                lambda_l1=9.491148511715021,\n",
       "                                lambda_l2=1.604404937631013e-08,\n",
       "                                learning_rate=0.14228155266790352, max_depth=19,\n",
       "                                min_child_samples=22, num_leaves=118))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False))]),\n",
       "                                 [&#x27;PassengerNum&#x27;, &#x27;HomePlanet&#x27;, &#x27;Destination&#x27;,\n",
       "                                  &#x27;CabinDeck&#x27;, &#x27;CabinSide&#x27;, &#x27;CryoSleep&#x27;, &#x27;VIP&#x27;,\n",
       "                                  &#x27;NameMissing&#x27;, &#x27;HomeMissing&#x27;,\n",
       "                                  &#x27;DestinationMissing&#x27;, &#x27;CabinMissing&#x27;,\n",
       "                                  &#x27;CryoMissing&#x27;, &#x27;VIPMissing&#x27;,\n",
       "                                  &#x27;FamilyGroupMember&#x27;, &#x27;YesRoomService&#x27;,\n",
       "                                  &#x27;YesFoodCourt&#x27;, &#x27;YesShoppingMall&#x27;,...\n",
       "                                  &#x27;YesVRDeck&#x27;, &#x27;YesTotalSpending&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  IterativeImputer(random_state=0)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;,\n",
       "                                  &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;,\n",
       "                                  &#x27;PartySize&#x27;]),\n",
       "                                (&#x27;ord&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;oe&#x27;, OrdinalEncoder()),\n",
       "                                                 (&#x27;imputer&#x27;,\n",
       "                                                  IterativeImputer(random_state=0)),\n",
       "                                                 (&#x27;rounder&#x27;, Rounder())]),\n",
       "                                 [&#x27;CabinBin&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;PassengerNum&#x27;, &#x27;HomePlanet&#x27;, &#x27;Destination&#x27;, &#x27;CabinDeck&#x27;, &#x27;CabinSide&#x27;, &#x27;CryoSleep&#x27;, &#x27;VIP&#x27;, &#x27;NameMissing&#x27;, &#x27;HomeMissing&#x27;, &#x27;DestinationMissing&#x27;, &#x27;CabinMissing&#x27;, &#x27;CryoMissing&#x27;, &#x27;VIPMissing&#x27;, &#x27;FamilyGroupMember&#x27;, &#x27;YesRoomService&#x27;, &#x27;YesFoodCourt&#x27;, &#x27;YesShoppingMall&#x27;, &#x27;YesSpa&#x27;, &#x27;YesVRDeck&#x27;, &#x27;YesTotalSpending&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;, &#x27;PartySize&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;IterativeImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.IterativeImputer.html\">?<span>Documentation for IterativeImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>IterativeImputer(random_state=0)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">ord</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;CabinBin&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OrdinalEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;IterativeImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.IterativeImputer.html\">?<span>Documentation for IterativeImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>IterativeImputer(random_state=0)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Rounder</label><div class=\"sk-toggleable__content fitted\"><pre>Rounder()</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.730228902545114, bagging_freq=2,\n",
       "               feature_fraction=0.9191598295606791, lambda_l1=9.491148511715021,\n",
       "               lambda_l2=1.604404937631013e-08,\n",
       "               learning_rate=0.14228155266790352, max_depth=19,\n",
       "               min_child_samples=22, num_leaves=118)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('one_hot',\n",
       "                                                                   OneHotEncoder(sparse_output=False))]),\n",
       "                                                  ['PassengerNum', 'HomePlanet',\n",
       "                                                   'Destination', 'CabinDeck',\n",
       "                                                   'CabinSide', 'CryoSleep',\n",
       "                                                   'VIP', 'NameMissing',\n",
       "                                                   'HomeMissing',\n",
       "                                                   'DestinationMissing',\n",
       "                                                   'CabinMissing',\n",
       "                                                   'CryoMissing', 'VIPMissing',\n",
       "                                                   'FamilyGroupMember',\n",
       "                                                   'YesRoomService',\n",
       "                                                   '...\n",
       "                                                                   IterativeImputer(random_state=0)),\n",
       "                                                                  ('rounder',\n",
       "                                                                   Rounder())]),\n",
       "                                                  ['CabinBin'])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('model',\n",
       "                 LGBMClassifier(bagging_fraction=0.730228902545114,\n",
       "                                bagging_freq=2,\n",
       "                                feature_fraction=0.9191598295606791,\n",
       "                                lambda_l1=9.491148511715021,\n",
       "                                lambda_l2=1.604404937631013e-08,\n",
       "                                learning_rate=0.14228155266790352, max_depth=19,\n",
       "                                min_child_samples=22, num_leaves=118))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bed6c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../ML_models_trained\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a80e4dd0bf5d3ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:26:33.779888Z",
     "start_time": "2024-08-21T16:26:32.984664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.491148511715021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.491148511715021\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9191598295606791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9191598295606791\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.730228902545114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.730228902545114\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.604404937631013e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.604404937631013e-08\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = lgbm_pipeline\n",
    "model.fit(X, y)\n",
    "\n",
    "with open(\n",
    "    \"../../ML_models_trained/light_gbm_model.pkl\",\n",
    "    \"wb\",\n",
    ") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3ba0c410150a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceship_titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
